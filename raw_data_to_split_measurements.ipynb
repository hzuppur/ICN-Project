{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impordi ja defineeri vajalikud meetodid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def make_splits(start, interval, time_before, time_after, measurements_count):\n",
    "    splits = []\n",
    "    if(measurements_count>0):\n",
    "        splits.append((start - timedelta(seconds=time_before), start + timedelta(seconds=time_after)))\n",
    "        splits.extend(make_splits(start + timedelta(seconds=interval),interval, time_before, time_after, measurements_count-1))\n",
    "    return splits\n",
    "\n",
    "def assign_range(times, splits):\n",
    "    c_ix = 0\n",
    "    in_split = False\n",
    "    ranges = []\n",
    "    for index, time in times.iteritems():\n",
    "        if(splits[c_ix][0] <= time <= splits[c_ix][1]):\n",
    "            in_split = True\n",
    "        elif(in_split == True):\n",
    "            if(c_ix +1 < len(splits)):\n",
    "                c_ix += 1\n",
    "            in_split = False\n",
    "\n",
    "        if(in_split):\n",
    "            ranges.append(str(splits[c_ix]))\n",
    "        else:\n",
    "            ranges.append(None)\n",
    "    ranges = np.array(ranges)\n",
    "    return ranges\n",
    "\n",
    "def window_rms(a, window_size):\n",
    "    a2 = np.power(a,2)\n",
    "    window = np.ones(window_size)/float(window_size)\n",
    "    return np.sqrt(np.convolve(a2, window, 'valid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defineeri muutujad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_file = './Recordings/17. January/Algus_17_33_01.txt'\n",
    "target_file = './Recordings/17. January/vastused_hain.txt'\n",
    "\n",
    "start_datetime = datetime(year=2020, month=1, day=17, hour=17, minute=33, second=0)\n",
    "interval = 10\n",
    "time_before = 1\n",
    "time_after = 3\n",
    "measurements_count = 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(recordings_file, skiprows=6, delimiter=\",\", names=np.arange(13))\n",
    "data = data.reset_index()\n",
    "data['datetime'] = data[12].apply(lambda x: datetime.fromtimestamp(x/1000.0))\n",
    "\n",
    "#siin vaata, mis kanalil brow ja mis kanalil cheek oli\n",
    "data = data[[2,3,5,'datetime']]\n",
    "data.columns = [\"unrailed\",\"brow\", \"cheek\", \"datetime\"]\n",
    "\n",
    "### Assign timestamps into ranges\n",
    "splits = make_splits(start_datetime, interval, time_before, time_after, measurements_count)\n",
    "splits[:5]\n",
    "data['ranges'] = assign_range(data['datetime'], splits)\n",
    "\n",
    "groups = data.groupby('ranges')\n",
    "groups_min = groups.size().min()\n",
    "\n",
    "cheek_array = groups['cheek'].apply(lambda x: x.head(groups_min)).values\n",
    "cheek_array = cheek_array.reshape(len(groups), groups_min)\n",
    "\n",
    "brow_array = groups['brow'].apply(lambda x: x.head(groups_min)).values\n",
    "brow_array = cheek_array.reshape(len(groups), groups_min)\n",
    "\n",
    "with open(target_file, 'r') as file:\n",
    "    lines = file.readlines()[1:]    \n",
    "\n",
    "pattern = r'(\\D)\\s(\\D)\\n'\n",
    "joined_lines = \"\\n\".join(lines)\n",
    "meta = re.findall(pattern,joined_lines)\n",
    "meta = np.array([list(m)for m in meta])\n",
    "meta = meta.T\n",
    "\n",
    "#truth or false\n",
    "decision = meta[0]\n",
    "\n",
    "# yes or no\n",
    "action = meta[1]\n",
    "\n",
    "meta[0] = meta[0] == 'T'\n",
    "meta[1] = meta[1] == 'J'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = len(os.listdir('./Processed_data/Cheek/'))\n",
    "\n",
    "with open(\"./Processed_data/Cheek/{}\".format(file_count+1), 'wb') as file:\n",
    "    np.save(file, cheek_array)\n",
    "    \n",
    "with open(\"./Processed_data/Brow/{}\".format(file_count+1), 'wb') as file:\n",
    "    np.save(file, brow_array)\n",
    "    \n",
    "with open(\"./Processed_data/Decisions/{}\".format(file_count+1), 'wb') as file:\n",
    "    np.save(file, meta)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#specify, what file nr to read\n",
    "file_nr = 1\n",
    "\n",
    "with open(\"./Processed_data/Cheek/{}\".format(file_nr), 'rb') as file:\n",
    "    cheek_array = np.load(file)\n",
    "    \n",
    "with open(\"./Processed_data/Brow/{}\".format(file_nr), 'rb') as file:\n",
    "    brow_array = np.load(file)\n",
    "    \n",
    "with open(\"./Processed_data/Decisions/{}\".format(file_nr), 'rb') as file:\n",
    "    meta = np.load(file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
